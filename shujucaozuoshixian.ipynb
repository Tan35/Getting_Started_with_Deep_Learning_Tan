{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入 torch，注意并不是导入 pytorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x\n",
    "# x 是一个向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们可以通过张量的 `shape` 属性来访问张量的形状和张量中元素的总数\n",
    "x.shape\n",
    "# 这个维度的长为 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()\n",
    "# 里面元素的总数，永远是个标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要改变一个张量的形状而不改变元素数量和元素值，我们可以调用 `reshape` 函数\n",
    "X = x.reshape(3, 4)\n",
    "X\n",
    "# “拧”成一个 3 x 4 的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们也可以创建一些元素比较特别的向量\n",
    "# 使用全 0、全 1、其他常量或者从特定分布中随机采样的数字\n",
    "torch.zeros((2, 3, 4)) # 可以理解为 2 个 3 行 4 列的二维数组组成的三维数组（元素全是 0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 同理 元素全为 1\n",
    "torch.ones((2, 3, 4)) # 同理，理解为 2 个 3 行 4 列的二维数组组成的三维数组（元素全是 1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以指定特定值来创建张量\n",
    "# 通过提供包含数值的 Python 列表（或嵌套列表）来为所需张量中的每个元元素赋予确定值\n",
    "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) # 使用了一个嵌套列表，这是一个二维的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 1, 4, 3],\n",
       "         [1, 2, 3, 4],\n",
       "         [4, 3, 2, 1]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果再加一个括号，就变成三维的\n",
    "torch.tensor([[[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印他的维数\n",
    "torch.tensor([[[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]]).shape\n",
    "# 其实就是看中括号层数来看张量（数组）是几维的。上面即为三维的，形状为 1 个 3 行 4 列 的数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 译为 张量 的意思，张量是任意数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建张量（数组）之后可以进行一些常见的标准算术运算（+、-、*、/ 和 **）都可以被升级为按元素运算\n",
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x-y, x * y, x / y, x**y, # ** 运算符是求幂运算，即对每个 x 中的元素求 y 元素的 幂次方\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还可以做其他一些运算\n",
    "# 比如说指数运算\n",
    "torch.exp(x) # 就是 e 的 x 次方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们也可以把多个张量连结在一起\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n",
    "# 这里的意思是生成 X,Y 这两个张量，并且把这两个张量拼接在一起\n",
    "# dim=0 表示在 行 合并，dim=1 表示在列合并（dim 如果不写这个参数默认是 0）\n",
    "# python 计数是从 0 开始，这里是一个二维张量合并，dim=0 就是第一个维度即行，dim=1 即第二个维度即列\n",
    "# dim 代表沿着此维连接张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还可以通过 逻辑运算符构建二元张量\n",
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对张量中所有元素进行求和会产生一个只有一个元素的张量\n",
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **广播机制**|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#即使形状不同，我们仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作\n",
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当两个张量形状不一样，我们可以有办法将两个张量形状变成一样\n",
    "# 但是前提是这两个张量维度一样，比如 a, b 都是二维的\n",
    "# 具体可以把 a 的 3 行 1 列中的 1 复制一份，变成 3 x 2\n",
    "# 把 b 的 1 行 2 列 中的 1 复制 3 分，变成 3 x 2，这样就可以相加了\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再来做一些元素的访问吧！\n",
    "# 可以用 [-1] 选择最后一个元素，可以用 [1:3] 选择第二个和第三个元素，即 [1:3] = (1,3]\n",
    "print(X)\n",
    "X[-1], X[1:3]\n",
    "# X[-1] 即把最后一行访问出来\n",
    "# X[1:3] 即把第二行和第三行访问出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  9.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 除读取之外，我们还可以通过指定索引来将元素写入矩阵\n",
    "X[1, 2] = 9\n",
    "X\n",
    "# 表示将 X 中 第一行第二列元素赋值为 9（注意注意 计数从 0 开始，别忘了）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为多个元素赋值相同的值，我们只需要索引所有元素，然后为他们赋值\n",
    "X[0:2, :] = 12\n",
    "X\n",
    "# 表示将第零行和第一行的所有元素赋值为 12，[0:2] = [0,2)。其他位置元素值不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 运行一些操作可能会导致为新结果分配内存\n",
    "before = id(Y)\n",
    "Y = Y + X\n",
    "# 把 Y+X 赋值为 Y，也就是说之前的内存已经被析构掉了\n",
    "# 内存析构，即销毁原来的变量，释放内存\n",
    "id(Y) == before\n",
    "# 新的 Y 的 id 不等于以前的，表示这两个 Y 并不是一样的，新的 Y 系统已经重新分配内存了\n",
    "# id(object) 表示 object 在 python 里面唯一的标识号，id() 是内存的十进制标识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 2702796114944\n",
      "id(Z): 2702796114944\n"
     ]
    }
   ],
   "source": [
    "# 如果做原地操作也有办法（也就是说不让系统重新分配内存）\n",
    "Z  = torch.zeros_like(Y) # 创建一个 Z 张量，元素全是 0 ，且和 Y 的形状和数据类型是一样的\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y # 再赋值 Z 中所有的元素，令所有元素的值为 X + Y ，其实就是对 Z 中所有元素进行一次改写\n",
    "print('id(Z):', id(Z))\n",
    "# 可以看出之前的 Z 和之后的 Z 的 id 是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 总结一下哈。上面的 Y 操作本质是产生了一个新的 Y\n",
    "# 而 Z 的操作是对 Z 的元素赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果我们在后续计算中没有重复使用 X，我们也可以使用 X[:] = X + Y 或 X += Y 来减少操作的内存开销\n",
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before\n",
    "# += 相当于 [:]，操作本质是赋值， X = X + Y 相当于 X 和 Y 加完又给了新创建的 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为 NumPy 张量\n",
    "A = X.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将大小为 1 的张量转换为 Python 标量\n",
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)\n",
    "# a.item() 是 numpy 的浮点数\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "issactan",
   "language": "python",
   "name": "issactan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
