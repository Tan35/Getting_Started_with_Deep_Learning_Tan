Hyperspectral data shape:  (145, 145, 200)
Label shape:  (145, 145)

... ... PCA tranformation ... ...
Hyperspectral data shape:  (145, 145, 200)
Label shape:  (145, 145)

... ... PCA tranformation ... ...
Data shape after PCA:  (145, 145, 30)

... ... create data cubes ... ...
Data shape after PCA:  (145, 145, 30)

... ... create data cubes ... ...
Data cube X shape:  (10249, 25, 25, 30)
Data cube y shape:  (10249,)

... ... create train & test data ... ...
Data cube X shape:  (10249, 25, 25, 30)
Data cube y shape:  (10249,)

... ... create train & test data ... ...
Xtrain shape:  (1024, 25, 25, 30)
Xtest  shape:  (9225, 25, 25, 30)
before transpose: Xtrain shape:  (1024, 25, 25, 30, 1)
before transpose: Xtest  shape:  (9225, 25, 25, 30, 1)
after transpose: Xtrain shape:  (1024, 1, 30, 25, 25)
after transpose: Xtest  shape:  (9225, 1, 30, 25, 25)
Cuda is available ✔
Xtrain shape:  (1024, 25, 25, 30)
Xtest  shape:  (9225, 25, 25, 30)
before transpose: Xtrain shape:  (1024, 25, 25, 30, 1)
before transpose: Xtest  shape:  (9225, 25, 25, 30, 1)
after transpose: Xtrain shape:  (1024, 1, 30, 25, 25)
after transpose: Xtest  shape:  (9225, 1, 30, 25, 25)
Cuda is available ✔
[Epoch: 1]   [loss avg: 11.3751]   [current loss: 2.3783]
[Epoch: 1]   [loss avg: 11.5853]   [current loss: 2.5701]
[Epoch: 2]   [loss avg: 9.5652]   [current loss: 1.6901][Epoch: 2]   [loss avg: 9.6836]   [current loss: 1.7959]

[Epoch: 3]   [loss avg: 8.2184]   [current loss: 1.2613][Epoch: 3]   [loss avg: 8.4906]   [current loss: 1.4700]

[Epoch: 4]   [loss avg: 7.1897]   [current loss: 0.9387]
[Epoch: 4]   [loss avg: 7.5563]   [current loss: 1.0869]
[Epoch: 5]   [loss avg: 6.3875]   [current loss: 0.7083][Epoch: 5]   [loss avg: 6.7452]   [current loss: 0.7295]

[Epoch: 6]   [loss avg: 5.6909]   [current loss: 0.5190]
[Epoch: 6]   [loss avg: 6.0437]   [current loss: 0.6113]
[Epoch: 7]   [loss avg: 5.0953]   [current loss: 0.3874]
[Epoch: 7]   [loss avg: 5.4657]   [current loss: 0.4924]
[Epoch: 8]   [loss avg: 4.6024]   [current loss: 0.3530][Epoch: 8]   [loss avg: 4.9752]   [current loss: 0.2722]

[Epoch: 9]   [loss avg: 4.1831]   [current loss: 0.2668]
[Epoch: 9]   [loss avg: 4.5456]   [current loss: 0.2315]
[Epoch: 10]   [loss avg: 3.8321]   [current loss: 0.1698][Epoch: 10]   [loss avg: 4.1752]   [current loss: 0.2099]

[Epoch: 11]   [loss avg: 3.5223]   [current loss: 0.1245][Epoch: 11]   [loss avg: 3.8569]   [current loss: 0.1672]

[Epoch: 12]   [loss avg: 3.2637]   [current loss: 0.0932]
[Epoch: 12]   [loss avg: 3.5761]   [current loss: 0.0857]
[Epoch: 13]   [loss avg: 3.0368]   [current loss: 0.1231]
[Epoch: 13]   [loss avg: 3.3376]   [current loss: 0.0982]
[Epoch: 14]   [loss avg: 2.8396]   [current loss: 0.0824][Epoch: 14]   [loss avg: 3.1223]   [current loss: 0.0577]

[Epoch: 15]   [loss avg: 2.6635]   [current loss: 0.0360][Epoch: 15]   [loss avg: 2.9304]   [current loss: 0.0660]

[Epoch: 16]   [loss avg: 2.5039]   [current loss: 0.0309]
[Epoch: 16]   [loss avg: 2.7596]   [current loss: 0.0413]
[Epoch: 17]   [loss avg: 2.3661]   [current loss: 0.0322]
[Epoch: 17]   [loss avg: 2.6140]   [current loss: 0.0611]
[Epoch: 18]   [loss avg: 2.2450]   [current loss: 0.0638]
[Epoch: 18]   [loss avg: 2.4800]   [current loss: 0.0455]
[Epoch: 19]   [loss avg: 2.1319]   [current loss: 0.0310]
[Epoch: 19]   [loss avg: 2.3579]   [current loss: 0.0331]
[Epoch: 20]   [loss avg: 2.0313]   [current loss: 0.0416][Epoch: 20]   [loss avg: 2.2465]   [current loss: 0.0359]

[Epoch: 21]   [loss avg: 1.9409]   [current loss: 0.0569]
[Epoch: 21]   [loss avg: 2.1479]   [current loss: 0.0220]
[Epoch: 22]   [loss avg: 1.8577]   [current loss: 0.0247][Epoch: 22]   [loss avg: 2.0589]   [current loss: 0.0675]

[Epoch: 23]   [loss avg: 1.7796]   [current loss: 0.0262]
[Epoch: 23]   [loss avg: 1.9820]   [current loss: 0.0791]
[Epoch: 24]   [loss avg: 1.7093]   [current loss: 0.0232]
[Epoch: 24]   [loss avg: 1.9050]   [current loss: 0.0289]
[Epoch: 25]   [loss avg: 1.6453]   [current loss: 0.0212][Epoch: 25]   [loss avg: 1.8348]   [current loss: 0.0537]

[Epoch: 26]   [loss avg: 1.5842]   [current loss: 0.0073][Epoch: 26]   [loss avg: 1.7662]   [current loss: 0.0135]

[Epoch: 27]   [loss avg: 1.5286]   [current loss: 0.0243][Epoch: 27]   [loss avg: 1.7050]   [current loss: 0.0148]

[Epoch: 28]   [loss avg: 1.4759]   [current loss: 0.0111]
[Epoch: 28]   [loss avg: 1.6461]   [current loss: 0.0179]
[Epoch: 29]   [loss avg: 1.4266]   [current loss: 0.0067][Epoch: 29]   [loss avg: 1.5907]   [current loss: 0.0042]

[Epoch: 30]   [loss avg: 1.3808]   [current loss: 0.0237][Epoch: 30]   [loss avg: 1.5413]   [current loss: 0.0412]

[Epoch: 31]   [loss avg: 1.3374]   [current loss: 0.0061]
[Epoch: 31]   [loss avg: 1.4928]   [current loss: 0.0106]
[Epoch: 32]   [loss avg: 1.2962]   [current loss: 0.0051][Epoch: 32]   [loss avg: 1.4479]   [current loss: 0.0225]

[Epoch: 33]   [loss avg: 1.2576]   [current loss: 0.0074]
[Epoch: 33]   [loss avg: 1.4058]   [current loss: 0.0046]
[Epoch: 34]   [loss avg: 1.2212]   [current loss: 0.0012]
[Epoch: 34]   [loss avg: 1.3658]   [current loss: 0.0040]
[Epoch: 35]   [loss avg: 1.1869]   [current loss: 0.0006][Epoch: 35]   [loss avg: 1.3292]   [current loss: 0.0225]

[Epoch: 36]   [loss avg: 1.1553]   [current loss: 0.0058]
[Epoch: 36]   [loss avg: 1.2932]   [current loss: 0.0058]
[Epoch: 37]   [loss avg: 1.1244]   [current loss: 0.0040][Epoch: 37]   [loss avg: 1.2601]   [current loss: 0.0420]

[Epoch: 38]   [loss avg: 1.0962]   [current loss: 0.0160]
[Epoch: 38]   [loss avg: 1.2274]   [current loss: 0.0072]
[Epoch: 39]   [loss avg: 1.0686]   [current loss: 0.0107][Epoch: 39]   [loss avg: 1.1965]   [current loss: 0.0016]

[Epoch: 40]   [loss avg: 1.0423]   [current loss: 0.0065]
[Epoch: 40]   [loss avg: 1.1672]   [current loss: 0.0059]
[Epoch: 41]   [loss avg: 1.0175]   [current loss: 0.0044]
[Epoch: 41]   [loss avg: 1.1394]   [current loss: 0.0046]
[Epoch: 42]   [loss avg: 0.9938]   [current loss: 0.0027][Epoch: 42]   [loss avg: 1.1133]   [current loss: 0.0068]

[Epoch: 43]   [loss avg: 0.9708]   [current loss: 0.0016][Epoch: 43]   [loss avg: 1.0880]   [current loss: 0.0027]

[Epoch: 44]   [loss avg: 0.9490]   [current loss: 0.0037]
[Epoch: 44]   [loss avg: 1.0645]   [current loss: 0.0031]
[Epoch: 45]   [loss avg: 0.9283]   [current loss: 0.0062][Epoch: 45]   [loss avg: 1.0415]   [current loss: 0.0032]

[Epoch: 46]   [loss avg: 0.9085]   [current loss: 0.0058]
[Epoch: 46]   [loss avg: 1.0198]   [current loss: 0.0063]
[Epoch: 47]   [loss avg: 0.8917]   [current loss: 0.0798]
[Epoch: 47]   [loss avg: 0.9993]   [current loss: 0.0234]
[Epoch: 48]   [loss avg: 0.8740]   [current loss: 0.0012]
[Epoch: 48]   [loss avg: 0.9788]   [current loss: 0.0028]
[Epoch: 49]   [loss avg: 0.8578]   [current loss: 0.0037]
[Epoch: 49]   [loss avg: 0.9593]   [current loss: 0.0035]
[Epoch: 50]   [loss avg: 0.8410]   [current loss: 0.0090]
[Epoch: 50]   [loss avg: 0.9411]   [current loss: 0.0073]
[Epoch: 51]   [loss avg: 0.8256]   [current loss: 0.0154]
[Epoch: 51]   [loss avg: 0.9234]   [current loss: 0.0034]
[Epoch: 52]   [loss avg: 0.8101]   [current loss: 0.0094]
[Epoch: 52]   [loss avg: 0.9069]   [current loss: 0.0430]
[Epoch: 53]   [loss avg: 0.7949]   [current loss: 0.0012]
[Epoch: 53]   [loss avg: 0.8903]   [current loss: 0.0042]
[Epoch: 54]   [loss avg: 0.7818]   [current loss: 0.0177]
[Epoch: 54]   [loss avg: 0.8741]   [current loss: 0.0034]
[Epoch: 55]   [loss avg: 0.7682]   [current loss: 0.0191]
[Epoch: 55]   [loss avg: 0.8608]   [current loss: 0.1371]
[Epoch: 56]   [loss avg: 0.7549]   [current loss: 0.0007]
[Epoch: 56]   [loss avg: 0.8465]   [current loss: 0.0415]
[Epoch: 57]   [loss avg: 0.7422]   [current loss: 0.0186][Epoch: 57]   [loss avg: 0.8324]   [current loss: 0.0190]

[Epoch: 58]   [loss avg: 0.7303]   [current loss: 0.0031]
[Epoch: 58]   [loss avg: 0.8191]   [current loss: 0.0114]
[Epoch: 59]   [loss avg: 0.7185]   [current loss: 0.0065]
[Epoch: 59]   [loss avg: 0.8068]   [current loss: 0.0037]
[Epoch: 60]   [loss avg: 0.7075]   [current loss: 0.0047]
[Epoch: 60]   [loss avg: 0.7938]   [current loss: 0.0130]
[Epoch: 61]   [loss avg: 0.6963]   [current loss: 0.0050]
[Epoch: 61]   [loss avg: 0.7811]   [current loss: 0.0070]
[Epoch: 62]   [loss avg: 0.6853]   [current loss: 0.0058]
[Epoch: 62]   [loss avg: 0.7692]   [current loss: 0.0192]
[Epoch: 63]   [loss avg: 0.6757]   [current loss: 0.0057]
[Epoch: 63]   [loss avg: 0.7576]   [current loss: 0.0029]
[Epoch: 64]   [loss avg: 0.6654]   [current loss: 0.0008]
[Epoch: 64]   [loss avg: 0.7459]   [current loss: 0.0023]
[Epoch: 65]   [loss avg: 0.6553]   [current loss: 0.0017][Epoch: 65]   [loss avg: 0.7355]   [current loss: 0.0304]

[Epoch: 66]   [loss avg: 0.6456]   [current loss: 0.0032]
[Epoch: 66]   [loss avg: 0.7247]   [current loss: 0.0033]
[Epoch: 67]   [loss avg: 0.6362]   [current loss: 0.0030]
[Epoch: 67]   [loss avg: 0.7146]   [current loss: 0.0147]
[Epoch: 68]   [loss avg: 0.6270]   [current loss: 0.0005]
[Epoch: 68]   [loss avg: 0.7045]   [current loss: 0.0030]
[Epoch: 69]   [loss avg: 0.6184]   [current loss: 0.0190][Epoch: 69]   [loss avg: 0.6951]   [current loss: 0.0146]

[Epoch: 70]   [loss avg: 0.6110]   [current loss: 0.0491]
[Epoch: 70]   [loss avg: 0.6855]   [current loss: 0.0038]
[Epoch: 71]   [loss avg: 0.6027]   [current loss: 0.0086][Epoch: 71]   [loss avg: 0.6760]   [current loss: 0.0009]

[Epoch: 72]   [loss avg: 0.5945]   [current loss: 0.0016]
[Epoch: 72]   [loss avg: 0.6673]   [current loss: 0.0130]
[Epoch: 73]   [loss avg: 0.5865]   [current loss: 0.0012][Epoch: 73]   [loss avg: 0.6587]   [current loss: 0.0010]

[Epoch: 74]   [loss avg: 0.5787]   [current loss: 0.0049][Epoch: 74]   [loss avg: 0.6500]   [current loss: 0.0034]

[Epoch: 75]   [loss avg: 0.5711]   [current loss: 0.0009]
[Epoch: 75]   [loss avg: 0.6418]   [current loss: 0.0030]
[Epoch: 76]   [loss avg: 0.5638]   [current loss: 0.0012]
[Epoch: 76]   [loss avg: 0.6336]   [current loss: 0.0002]
[Epoch: 77]   [loss avg: 0.5566]   [current loss: 0.0048]
[Epoch: 77]   [loss avg: 0.6259]   [current loss: 0.0282]
[Epoch: 78]   [loss avg: 0.5496]   [current loss: 0.0023]
[Epoch: 78]   [loss avg: 0.6179]   [current loss: 0.0009]
[Epoch: 79]   [loss avg: 0.5432]   [current loss: 0.0446][Epoch: 79]   [loss avg: 0.6107]   [current loss: 0.0020]

[Epoch: 80]   [loss avg: 0.5365]   [current loss: 0.0053]
[Epoch: 80]   [loss avg: 0.6035]   [current loss: 0.0079]
[Epoch: 81]   [loss avg: 0.5300]   [current loss: 0.0010]
[Epoch: 81]   [loss avg: 0.5965]   [current loss: 0.0176]
[Epoch: 82]   [loss avg: 0.5237]   [current loss: 0.0080]
[Epoch: 82]   [loss avg: 0.5896]   [current loss: 0.0201]
[Epoch: 83]   [loss avg: 0.5174]   [current loss: 0.0017]
[Epoch: 83]   [loss avg: 0.5827]   [current loss: 0.0044]
[Epoch: 84]   [loss avg: 0.5115]   [current loss: 0.0017]
[Epoch: 84]   [loss avg: 0.5759]   [current loss: 0.0011]
[Epoch: 85]   [loss avg: 0.5056]   [current loss: 0.0075][Epoch: 85]   [loss avg: 0.5692]   [current loss: 0.0007]

[Epoch: 86]   [loss avg: 0.4998]   [current loss: 0.0003][Epoch: 86]   [loss avg: 0.5626]   [current loss: 0.0008]

[Epoch: 87]   [loss avg: 0.5564]   [current loss: 0.0116][Epoch: 87]   [loss avg: 0.4941]   [current loss: 0.0024]

[Epoch: 88]   [loss avg: 0.4887]   [current loss: 0.0022]
[Epoch: 88]   [loss avg: 0.5501]   [current loss: 0.0004]
[Epoch: 89]   [loss avg: 0.4836]   [current loss: 0.0009]
[Epoch: 89]   [loss avg: 0.5440]   [current loss: 0.0048]
[Epoch: 90]   [loss avg: 0.4783]   [current loss: 0.0038][Epoch: 90]   [loss avg: 0.5381]   [current loss: 0.0005]

[Epoch: 91]   [loss avg: 0.4731]   [current loss: 0.0018]
[Epoch: 91]   [loss avg: 0.5325]   [current loss: 0.0264]
[Epoch: 92]   [loss avg: 0.4681]   [current loss: 0.0035]
[Epoch: 92]   [loss avg: 0.5278]   [current loss: 0.0527]
[Epoch: 93]   [loss avg: 0.4632]   [current loss: 0.0027]
[Epoch: 93]   [loss avg: 0.5224]   [current loss: 0.0021]
[Epoch: 94]   [loss avg: 0.4584]   [current loss: 0.0037]
[Epoch: 94]   [loss avg: 0.5173]   [current loss: 0.0275]
[Epoch: 95]   [loss avg: 0.4538]   [current loss: 0.0178][Epoch: 95]   [loss avg: 0.5123]   [current loss: 0.0029]

[Epoch: 96]   [loss avg: 0.4492]   [current loss: 0.0008][Epoch: 96]   [loss avg: 0.5074]   [current loss: 0.0378]

[Epoch: 97]   [loss avg: 0.4447]   [current loss: 0.0014][Epoch: 97]   [loss avg: 0.5023]   [current loss: 0.0097]

[Epoch: 98]   [loss avg: 0.4403]   [current loss: 0.0019]
[Epoch: 98]   [loss avg: 0.4974]   [current loss: 0.0002]
[Epoch: 99]   [loss avg: 0.4359]   [current loss: 0.0027]
[Epoch: 99]   [loss avg: 0.4928]   [current loss: 0.0065]
[Epoch: 100]   [loss avg: 0.4316]   [current loss: 0.0006]
[Epoch: 100]   [loss avg: 0.4881]   [current loss: 0.0022]
Training time: 25.215206623077393
Finished TrainingTraining time: 25.215717554092407

Finished Training
              precision    recall  f1-score   support

         0.0     0.8864    0.9512    0.9176        41
         1.0     0.9880    0.9642    0.9760      1285
         2.0     0.9987    0.9973    0.9980       747
         3.0     1.0000    1.0000    1.0000       213
         4.0     1.0000    0.9977    0.9988       435
         5.0     0.9804    0.9909    0.9856       657
         6.0     1.0000    1.0000    1.0000        25
         7.0     1.0000    1.0000    1.0000       430
         8.0     1.0000    1.0000    1.0000        18
         9.0     0.9829    0.9851    0.9840       875
        10.0     0.9793    0.9824    0.9808      2210
        11.0     0.9925    0.9869    0.9897       534
        12.0     1.0000    1.0000    1.0000       185
        13.0     0.9879    1.0000    0.9939      1139
        14.0     0.9971    0.9971    0.9971       347
        15.0     0.9425    0.9762    0.9591        84

    accuracy                         0.9871      9225
   macro avg     0.9835    0.9893    0.9863      9225
weighted avg     0.9872    0.9871    0.9871      9225

              precision    recall  f1-score   support

         0.0     0.8864    0.9512    0.9176        41
         1.0     0.9888    0.9642    0.9764      1285
         2.0     0.9987    0.9987    0.9987       747
         3.0     1.0000    1.0000    1.0000       213
         4.0     1.0000    0.9977    0.9988       435
         5.0     0.9804    0.9909    0.9856       657
         6.0     1.0000    1.0000    1.0000        25
         7.0     1.0000    1.0000    1.0000       430
         8.0     1.0000    1.0000    1.0000        18
         9.0     0.9829    0.9851    0.9840       875
        10.0     0.9793    0.9824    0.9808      2210
        11.0     0.9943    0.9869    0.9906       534
        12.0     1.0000    1.0000    1.0000       185
        13.0     0.9870    1.0000    0.9935      1139
        14.0     0.9971    0.9971    0.9971       347
        15.0     0.9425    0.9762    0.9591        84

    accuracy                         0.9872      9225
   macro avg     0.9836    0.9894    0.9864      9225
weighted avg     0.9873    0.9872    0.9872      9225

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
